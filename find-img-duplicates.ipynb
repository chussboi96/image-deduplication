{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64eea54c-7725-4f40-b845-1f6b980e65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from imagededup.methods import PHash\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0db3072-8625-4948-9d27-768b87cffd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_exact_duplicates(directories):\n",
    "    hasher = PHash()\n",
    "    directory = directories[0]  # Only one directory provided\n",
    "    directory_path = Path(directory)    \n",
    "    if not directory_path.exists():\n",
    "        print(f\"Directory {directory} does not exist.\")\n",
    "        return\n",
    "    print(f\"Processing directory: {directory}\")\n",
    "    \n",
    "    # Compute hashes for images in the directory\n",
    "    encodings = hasher.encode_images(image_dir=directory, recursive=True)\n",
    "    \n",
    "    if not encodings:\n",
    "        print(\"No images found in the specified directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(encodings)} images. Computing duplicates...\")\n",
    "    \n",
    "    # Find duplicates based on identical hashes\n",
    "    duplicates = hasher.find_duplicates(encoding_map=encodings, max_distance_threshold=0)\n",
    "    \n",
    "    # Filter and collect duplicate pairs\n",
    "    duplicate_pairs = []\n",
    "    processed_files = set()\n",
    "    for img, duplicates_list in duplicates.items():\n",
    "        if duplicates_list and img not in processed_files:\n",
    "            for dup_img in duplicates_list:\n",
    "                if dup_img not in processed_files:\n",
    "                    duplicate_pairs.append((img, dup_img))\n",
    "                    processed_files.add(dup_img)\n",
    "            processed_files.add(img)\n",
    "    \n",
    "    # Output results\n",
    "    if duplicate_pairs:\n",
    "        print(\"\\nFound the following exact duplicate image pairs:\")\n",
    "        for img1, img2 in duplicate_pairs:\n",
    "            print(f\"Duplicate pair: {img1} <-> {img2}\")\n",
    "        print(f\"Total duplicate pairs found: {len(duplicate_pairs)}\")\n",
    "    else:\n",
    "        print(\"\\nNo exact duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cec4b19-e130-4900-b3f3-2c2e4eaea77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 02:39:25,198: INFO Start: Calculating hashes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: D:\\research dataset\\cloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 754/754 [00:24<00:00, 30.55it/s]\n",
      "2025-05-20 02:39:54,578: INFO End: Calculating hashes!\n",
      "C:\\Users\\LOQ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imagededup\\methods\\hashing.py:317: RuntimeWarning: Parameter num_enc_workers has no effect since encodings are already provided\n",
      "  warnings.warn('Parameter num_enc_workers has no effect since encodings are already provided', RuntimeWarning)\n",
      "2025-05-20 02:39:54,581: INFO Start: Evaluating hamming distances for getting duplicates\n",
      "2025-05-20 02:39:54,582: INFO Start: Retrieving duplicates using BKTree algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 705 images. Computing duplicates...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 705/705 [00:17<00:00, 40.11it/s]\n",
      "2025-05-20 02:40:16,462: INFO End: Retrieving duplicates using BKTree algorithm\n",
      "2025-05-20 02:40:16,464: INFO End: Evaluating hamming distances for getting duplicates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found the following exact duplicate image pairs:\n",
      "Duplicate pair: 00017.png <-> 00019.png\n",
      "Duplicate pair: 00026.png <-> 00033.png\n",
      "Duplicate pair: 00031.png <-> 00032.png\n",
      "Duplicate pair: 00331.png <-> 00332.png\n",
      "Total duplicate pairs found: 4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # directory containing the images\n",
    "    directories = [\n",
    "        r\"D:\\research dataset\\cloth\",\n",
    "    ]\n",
    "    find_exact_duplicates(directories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
